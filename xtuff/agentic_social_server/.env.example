# AI Social Server Environment Configuration
# Copy this file to .env and fill in your actual values

# ======================
# LLM API KEYS
# ======================

# Google Gemini API Key (for native Gemini integration)
GOOGLE_API_KEY=your_google_api_key_here
GEMINI_API_KEY=your_google_api_key_here

# OpenAI API Key (for GPT models via litellm)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Key (for Claude models via litellm)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Groq API Key (for fast inference)
GROQ_API_KEY=your_groq_api_key_here

# Other LLM providers (optional)
REPLICATE_API_TOKEN=your_replicate_token_here
XAI_API_KEY=your_xai_api_key_here

# ======================
# APPLICATION SETTINGS
# ======================

# Local host URL for development
LOCAL_HOST=http://localhost:8501

# Application name and branding
APP_NAME=AI Social Server

# ======================
# OPTIONAL INTEGRATIONS
# ======================

# Google Custom Search (for web search features)
GOOGLE_CSE_ID=your_custom_search_engine_id

# Helicone (for LLM observability)
HELICONE_API_KEY=your_helicone_api_key

# ======================
# DEVELOPMENT SETTINGS
# ======================

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Enable/disable features
ENABLE_AUTO_GENERATION=true
ENABLE_ANALYTICS=false

# ======================
# NOTES
# ======================
#
# Required for basic functionality:
# - GOOGLE_API_KEY or GEMINI_API_KEY (for Gemini 2.5 Pro integration)
# - At least one other LLM API key (OpenAI, Anthropic, etc.)
#
# The app will work with just Google API key due to native Gemini integration
# but having backup LLM providers ensures reliability