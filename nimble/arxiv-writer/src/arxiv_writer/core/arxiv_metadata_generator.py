#!/usr/bin/env python3
"""
ArXiv Metadata Generation and Preparation Tools

This module generates proper metadata for arXiv submissions including
categories, abstracts, and submission forms.
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from datetime import datetime

@dataclass
class ArxivMetadata:
    """ArXiv submission metadata."""
    title: str
    authors: List[Dict[str, str]]  # [{"name": "...", "email": "...", "affiliation": "..."}]
    abstract: str
    categories: List[str]
    primary_category: str
    keywords: List[str]
    comments: Optional[str] = None
    msc_class: Optional[str] = None
    acm_class: Optional[str] = None
    journal_ref: Optional[str] = None
    doi: Optional[str] = None
    license: str = "arXiv.org perpetual, non-exclusive license"

class ArxivMetadataGenerator:
    """Generate arXiv submission metadata."""
    
    # ArXiv category mappings
    CATEGORY_DESCRIPTIONS = {
        'cs.AI': 'Artificial Intelligence',
        'cs.HC': 'Human-Computer Interaction',
        'cs.CL': 'Computation and Language',
        'cs.LG': 'Machine Learning',
        'cs.SE': 'Software Engineering',
        'cs.IR': 'Information Retrieval',
        'cs.DL': 'Digital Libraries'
    }
    
    def __init__(self, paper_dir: str):
        """Initialize metadata generator."""
        self.paper_dir = Path(paper_dir)
        self.latex_dir = self.paper_dir / "latex"
        
    def extract_metadata_from_latex(self) -> ArxivMetadata:
        """Extract metadata from LaTeX files."""
        # Read main.tex and preamble.tex
        main_tex = self.latex_dir / "main.tex"
        preamble_tex = self.latex_dir / "preamble.tex"
        abstract_tex = self.latex_dir / "abstract.tex"
        
        title = self._extract_title(main_tex, preamble_tex)
        authors = self._extract_authors(main_tex, preamble_tex)
        abstract = self._extract_abstract(abstract_tex, main_tex)
        categories = self._determine_categories()
        keywords = self._extract_keywords()
        
        return ArxivMetadata(
            title=title,
            authors=authors,
            abstract=abstract,
            categories=categories,
            primary_category=categories[0] if categories else 'cs.AI',
            keywords=keywords,
            comments=f"Generated by Codexes-Factory ArXiv Paper Generator on {datetime.now().strftime('%Y-%m-%d')}"
        )
    
    def _extract_title(self, main_tex: Path, preamble_tex: Path) -> str:
        """Extract title from LaTeX files."""
        for tex_file in [preamble_tex, main_tex]:
            if tex_file.exists():
                try:
                    content = tex_file.read_text(encoding='utf-8')
                    title_match = re.search(r'\\title\{([^}]+)\}', content)
                    if title_match:
                        title = title_match.group(1)
                        # Clean up LaTeX commands
                        title = re.sub(r'\\[a-zA-Z]+\{([^}]*)\}', r'\1', title)
                        title = title.replace('\\\\', ' ').strip()
                        return title
                except Exception:
                    continue
        
        return "AI-Assisted Creation of a Publishing Imprint: The xynapse_traces Case Study"
    
    def _extract_authors(self, main_tex: Path, preamble_tex: Path) -> List[Dict[str, str]]:
        """Extract author information from LaTeX files."""
        authors = []
        
        for tex_file in [preamble_tex, main_tex]:
            if tex_file.exists():
                try:
                    content = tex_file.read_text(encoding='utf-8')
                    author_match = re.search(r'\\author\{([^}]+)\}', content, re.DOTALL)
                    if author_match:
                        author_text = author_match.group(1)
                        
                        # Extract email - try multiple patterns
                        email = ""
                        email_patterns = [
                            r'\\texttt\{([^}]+@[^}]+)\}',
                            r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})',
                            r'texttt\{([^}]+@[^}]+)\}'
                        ]
                        
                        for pattern in email_patterns:
                            email_match = re.search(pattern, author_text)
                            if email_match:
                                email = email_match.group(1)
                                break
                        
                        # Extract name and affiliation
                        lines = [line.strip() for line in author_text.split('\\\\') if line.strip()]
                        
                        # First line is usually the name
                        name = lines[0] if lines else "AI Lab for Book-Lovers"
                        
                        # Last line is usually affiliation (if not email)
                        affiliation = "Nimble Books LLC"
                        if len(lines) > 1:
                            last_line = lines[-1]
                            if '@' not in last_line:  # Not an email line
                                affiliation = last_line
                        
                        # Clean up LaTeX commands
                        name = re.sub(r'\\[a-zA-Z]+\*?\{([^}]*)\}', r'\1', name)
                        name = re.sub(r'\\[a-zA-Z]+\*?', '', name).strip()
                        
                        affiliation = re.sub(r'\\[a-zA-Z]+\*?\{([^}]*)\}', r'\1', affiliation)
                        affiliation = re.sub(r'\\[a-zA-Z]+\*?', '', affiliation).strip()
                        
                        # If no email found, use default
                        if not email:
                            email = "wfz@nimblebooks.com"
                        
                        authors.append({
                            "name": name,
                            "email": email,
                            "affiliation": affiliation
                        })
                        break
                except Exception:
                    continue
        
        if not authors:
            authors = [{
                "name": "AI Lab for Book-Lovers",
                "email": "wfz@nimblebooks.com",
                "affiliation": "Nimble Books LLC"
            }]
        
        return authors
    
    def _extract_abstract(self, abstract_tex: Path, main_tex: Path) -> str:
        """Extract abstract from LaTeX files."""
        # Try abstract.tex first
        if abstract_tex.exists():
            try:
                content = abstract_tex.read_text(encoding='utf-8')
                
                # Remove LaTeX section headers and labels
                abstract = re.sub(r'%.*?\n', '', content)  # Remove comments
                abstract = re.sub(r'\\section\*?\{[^}]*\}', '', abstract)  # Remove section headers
                abstract = re.sub(r'\\label\{[^}]*\}', '', abstract)  # Remove labels
                abstract = re.sub(r'\\begin\{abstract\}', '', abstract)
                abstract = re.sub(r'\\end\{abstract\}', '', abstract)
                
                # Clean up LaTeX commands but preserve content
                abstract = re.sub(r'\\[a-zA-Z]+\*?\{([^}]*)\}', r'\1', abstract)
                abstract = re.sub(r'\\[a-zA-Z]+\*?', '', abstract)
                
                # Clean up whitespace and formatting
                abstract = re.sub(r'\n\s*\n', '\n\n', abstract)  # Normalize paragraph breaks
                abstract = re.sub(r'^\s*Abstract\s*\n', '', abstract, flags=re.IGNORECASE)  # Remove "Abstract" header
                abstract = abstract.strip()
                
                if abstract and len(abstract) > 50:
                    return abstract
            except Exception:
                pass
        
        # Try main.tex
        if main_tex.exists():
            try:
                content = main_tex.read_text(encoding='utf-8')
                abstract_match = re.search(r'\\begin\{abstract\}(.*?)\\end\{abstract\}', content, re.DOTALL)
                if abstract_match:
                    abstract = abstract_match.group(1).strip()
                    abstract = re.sub(r'\\[a-zA-Z]+\*?\{([^}]*)\}', r'\1', abstract)
                    abstract = re.sub(r'\\[a-zA-Z]+\*?', '', abstract)
                    return abstract.strip()
            except Exception:
                pass
        
        # Default abstract
        return ("This paper presents a comprehensive case study of AI-assisted creation of a publishing imprint, "
                "focusing on the xynapse_traces imprint developed using the Codexes-Factory platform. "
                "We demonstrate how artificial intelligence can streamline the entire publishing workflow, "
                "from manuscript analysis to distribution-ready file generation, showcasing significant "
                "improvements in production timelines and resource allocation.")
    
    def _determine_categories(self) -> List[str]:
        """Determine appropriate arXiv categories."""
        # Based on the paper content, these are the most appropriate categories
        return ['cs.AI', 'cs.HC']
    
    def _extract_keywords(self) -> List[str]:
        """Extract or generate keywords."""
        # Check if keywords are defined in preamble
        preamble_tex = self.latex_dir / "preamble.tex"
        if preamble_tex.exists():
            try:
                content = preamble_tex.read_text(encoding='utf-8')
                keywords_match = re.search(r'pdfkeywords=\{([^}]+)\}', content)
                if keywords_match:
                    keywords_text = keywords_match.group(1)
                    return [kw.strip() for kw in keywords_text.split(',')]
            except Exception:
                pass
        
        # Default keywords based on paper content
        return [
            'artificial intelligence',
            'publishing automation',
            'digital humanities',
            'content generation',
            'multilingual processing',
            'configuration management'
        ]
    
    def generate_arxiv_submission_form(self, metadata: ArxivMetadata) -> str:
        """Generate arXiv submission form text."""
        form_text = []
        
        form_text.append("ArXiv Submission Form")
        form_text.append("=" * 50)
        form_text.append("")
        
        form_text.append(f"Title: {metadata.title}")
        form_text.append("")
        
        form_text.append("Authors:")
        for i, author in enumerate(metadata.authors, 1):
            form_text.append(f"  {i}. {author['name']}")
            form_text.append(f"     Email: {author['email']}")
            form_text.append(f"     Affiliation: {author['affiliation']}")
            form_text.append("")
        
        form_text.append(f"Primary Category: {metadata.primary_category} ({self.CATEGORY_DESCRIPTIONS.get(metadata.primary_category, '')})")
        form_text.append("")
        
        if len(metadata.categories) > 1:
            form_text.append("Additional Categories:")
            for cat in metadata.categories[1:]:
                form_text.append(f"  - {cat} ({self.CATEGORY_DESCRIPTIONS.get(cat, '')})")
            form_text.append("")
        
        form_text.append("Abstract:")
        form_text.append("-" * 20)
        form_text.append(metadata.abstract)
        form_text.append("")
        
        form_text.append("Keywords:")
        form_text.append(", ".join(metadata.keywords))
        form_text.append("")
        
        if metadata.comments:
            form_text.append(f"Comments: {metadata.comments}")
            form_text.append("")
        
        form_text.append(f"License: {metadata.license}")
        form_text.append("")
        
        return "\n".join(form_text)
    
    def generate_submission_metadata_json(self, metadata: ArxivMetadata) -> Dict[str, Any]:
        """Generate JSON metadata for submission."""
        return {
            "title": metadata.title,
            "authors": metadata.authors,
            "abstract": metadata.abstract,
            "categories": {
                "primary": metadata.primary_category,
                "secondary": metadata.categories[1:] if len(metadata.categories) > 1 else []
            },
            "keywords": metadata.keywords,
            "comments": metadata.comments,
            "license": metadata.license,
            "submission_date": datetime.now().isoformat(),
            "arxiv_categories": {
                cat: self.CATEGORY_DESCRIPTIONS.get(cat, '') 
                for cat in metadata.categories
            }
        }
    
    def create_arxiv_ready_abstract(self, metadata: ArxivMetadata) -> str:
        """Create arXiv-ready abstract with proper formatting."""
        abstract = metadata.abstract
        
        # Ensure proper length (150-300 words typically)
        words = abstract.split()
        if len(words) < 100:
            # Extend if too short
            extension = (" This work contributes to the growing field of AI-assisted publishing "
                        "by demonstrating practical applications of large language models in "
                        "content creation, metadata generation, and workflow automation.")
            abstract += extension
        elif len(words) > 300:
            # Truncate if too long
            abstract = " ".join(words[:300]) + "..."
        
        return abstract
    
    def validate_metadata(self, metadata: ArxivMetadata) -> List[str]:
        """Validate metadata for arXiv submission."""
        issues = []
        
        # Check title
        if not metadata.title or len(metadata.title.strip()) < 10:
            issues.append("Title is too short or missing")
        
        # Check authors
        if not metadata.authors:
            issues.append("No authors specified")
        else:
            for i, author in enumerate(metadata.authors):
                if not author.get('name'):
                    issues.append(f"Author {i+1} missing name")
                if not author.get('email') or '@' not in author.get('email', ''):
                    issues.append(f"Author {i+1} missing valid email")
        
        # Check abstract
        if not metadata.abstract or len(metadata.abstract.strip()) < 50:
            issues.append("Abstract is too short or missing")
        
        # Check categories
        if not metadata.categories:
            issues.append("No categories specified")
        elif metadata.primary_category not in self.CATEGORY_DESCRIPTIONS:
            issues.append(f"Invalid primary category: {metadata.primary_category}")
        
        # Check keywords
        if not metadata.keywords or len(metadata.keywords) < 3:
            issues.append("Need at least 3 keywords")
        
        return issues


def main():
    """Main function for command-line usage."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Generate arXiv submission metadata")
    parser.add_argument("paper_dir", help="Directory containing the paper")
    parser.add_argument("--output", "-o", help="Output directory for metadata files")
    parser.add_argument("--validate", action="store_true", help="Validate metadata only")
    
    args = parser.parse_args()
    
    generator = ArxivMetadataGenerator(args.paper_dir)
    metadata = generator.extract_metadata_from_latex()
    
    if args.validate:
        issues = generator.validate_metadata(metadata)
        if issues:
            print("Metadata validation issues:")
            for issue in issues:
                print(f"  âŒ {issue}")
            return 1
        else:
            print("âœ… Metadata validation passed")
            return 0
    
    # Generate output files
    output_dir = Path(args.output) if args.output else Path(args.paper_dir) / "submission"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Generate submission form
    form_text = generator.generate_arxiv_submission_form(metadata)
    with open(output_dir / "arxiv_submission_form.txt", 'w') as f:
        f.write(form_text)
    
    # Generate JSON metadata
    json_metadata = generator.generate_submission_metadata_json(metadata)
    with open(output_dir / "submission_metadata.json", 'w') as f:
        json.dump(json_metadata, f, indent=2)
    
    # Generate arXiv-ready abstract
    arxiv_abstract = generator.create_arxiv_ready_abstract(metadata)
    with open(output_dir / "arxiv_abstract.txt", 'w') as f:
        f.write(arxiv_abstract)
    
    print(f"ðŸ“ Metadata files generated in: {output_dir}")
    print(f"   - arxiv_submission_form.txt")
    print(f"   - submission_metadata.json")
    print(f"   - arxiv_abstract.txt")
    
    # Validate
    issues = generator.validate_metadata(metadata)
    if issues:
        print("\nâš ï¸  Metadata validation issues:")
        for issue in issues:
            print(f"   - {issue}")
    else:
        print("\nâœ… Metadata validation passed")
    
    return 0


if __name__ == "__main__":
    exit(main())