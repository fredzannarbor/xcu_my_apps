# src/codexes/modules/distribution/lsi_acs_generator.py

import os
import csv
import logging
from typing import Optional, List
from ..metadata.metadata_models import CodexMetadata
from .field_mapping import FieldMappingRegistry, create_default_lsi_registry
from ..verifiers.validation_framework import LSIValidationPipeline
from .lsi_configuration import LSIConfiguration
from .lsi_logging_manager import LSILoggingManager


print("Defining LsiAcsGenerator class...")

class LsiAcsGenerator:
    """
    Generates LSI ACS-compatible CSV files from CodexMetadata objects.
    Enhanced with field mapping strategies, validation pipeline, and configuration management.
    """

    def __init__(self, template_path: str, config_path: Optional[str] = None, log_directory: str = "logs/lsi_generation"):
        """
        Initialize the LSI ACS Generator.
        
        Args:
            template_path: Path to the LSI template CSV file
            config_path: Optional path to configuration file
            log_directory: Directory for detailed logging
        """
        self.template_path = template_path
        if not os.path.exists(template_path):
            raise FileNotFoundError(f"Template file not found: {template_path}")
        
        # Initialize comprehensive logging manager
        self.logging_manager = LSILoggingManager(log_directory)
        
        # Initialize configuration management
        self.config = LSIConfiguration(config_path)
        
        # Initialize field mapping registry with default strategies
        self.field_registry = create_default_lsi_registry()
        
        # Initialize validation pipeline
        self.validation_pipeline = LSIValidationPipeline()
        
        # Load and register additional field mappings from configuration
        self._setup_enhanced_field_mappings()
        
        # Initialize advanced territorial pricing strategy
        self._setup_advanced_pricing()
        
        self.logging_manager.log_info(f"LSI ACS Generator initialized with {len(self.field_registry.get_registered_fields())} field mappings")

    def _setup_enhanced_field_mappings(self):
        """Setup enhanced field mappings from configuration and add missing LSI fields."""
        from .field_mapping import DirectMappingStrategy, DefaultMappingStrategy, ComputedMappingStrategy
        
        # Register additional LSI-specific fields that weren't in the default registry
        additional_mappings = {
            # LSI Account and submission info
            "Lightning Source Account #": DirectMappingStrategy("lightning_source_account", 
                                                              self.config.get_default_value("Lightning Source Account #")),
            "Metadata Contact Dictionary": DirectMappingStrategy("metadata_contact_dictionary"),
            "Parent ISBN": DirectMappingStrategy("parent_isbn"),
            "Cover/Jacket Submission Method": DirectMappingStrategy("cover_submission_method", "FTP"),
            "Text Block SubmissionMethod": DirectMappingStrategy("text_block_submission_method", "FTP"),
            
            # Physical specifications
            "Weight(Lbs)": ComputedMappingStrategy(self._compute_weight),
            "Carton Pack Quantity": DirectMappingStrategy("carton_pack_quantity", "1"),
            
            # Publication timing
            "Street Date": DirectMappingStrategy("street_date"),
            
            # Territorial rights
            "Territorial Rights": DirectMappingStrategy("territorial_rights", "World"),
            
            # Returnability - use computed strategy to handle territorial differences
            "Returnable": ComputedMappingStrategy(self._compute_returnability),
            
            # Edition information
            "Edition Number": DirectMappingStrategy("edition_number"),
            "Edition Description": DirectMappingStrategy("edition_description"),
            
            # File paths
            "Jacket Path / Filename": DirectMappingStrategy("jacket_path_filename"),
            "Interior Path / Filename": DirectMappingStrategy("interior_path_filename"),
            "Cover Path / Filename": DirectMappingStrategy("cover_path_filename"),
            
            # Enhanced contributor information
            "Contributor One BIO": DirectMappingStrategy("contributor_one_bio"),
            "Contributor One Affiliations": DirectMappingStrategy("contributor_one_affiliations"),
            "Contributor One Professional Position": DirectMappingStrategy("contributor_one_professional_position"),
            "Contributor One Location": DirectMappingStrategy("contributor_one_location"),
            "Contributor One Location Type Code": DirectMappingStrategy("contributor_one_location_type_code"),
            "Contributor One Prior Work": DirectMappingStrategy("contributor_one_prior_work"),
            
            # LSI Special fields
            "LSI Special Category  (please consult LSI before using": DirectMappingStrategy("lsi_special_category"),
            "Stamped Text LEFT": DirectMappingStrategy("stamped_text_left"),
            "Stamped Text CENTER": DirectMappingStrategy("stamped_text_center"),
            "Stamped Text RIGHT": DirectMappingStrategy("stamped_text_right"),
            "Order Type Eligibility": DirectMappingStrategy("order_type_eligibility"),
            
            # LSI Flex fields
            "LSI FlexField1 (please consult LSI before using)": DirectMappingStrategy("lsi_flexfield1"),
            "LSI FlexField2 (please consult LSI before using)": DirectMappingStrategy("lsi_flexfield2"),
            "LSI FlexField3 (please consult LSI before using)": DirectMappingStrategy("lsi_flexfield3"),
            "LSI FlexField4 (please consult LSI before using)": DirectMappingStrategy("lsi_flexfield4"),
            "LSI FlexField5 (please consult LSI before using)": DirectMappingStrategy("lsi_flexfield5"),
            
            # Publisher reference
            "Publisher Reference ID": DirectMappingStrategy("publisher_reference_id"),
            
            # Marketing
            "Marketing Image": DirectMappingStrategy("marketing_image"),
            
            # Reserved fields - leave empty by default
            "Reserved 1": DefaultMappingStrategy(""),
            "Reserved 2": DefaultMappingStrategy(""),
            "Reserved 3": DefaultMappingStrategy(""),
            "Reserved 4": DefaultMappingStrategy(""),
            "Reserved5": DefaultMappingStrategy(""),
            "Reserved6": DefaultMappingStrategy(""),
            "Reserved7": DefaultMappingStrategy(""),
            "Reserved8": DefaultMappingStrategy(""),
            "Reserved (Special Instructions)": DefaultMappingStrategy(""),
            "Reserved9": DefaultMappingStrategy(""),
            "Reserved10": DefaultMappingStrategy(""),
            "Reserved11": DefaultMappingStrategy(""),
            "Reserved12": DefaultMappingStrategy(""),
            
            # Additional BISAC categories
            "BISAC Category 2": DirectMappingStrategy("bisac_category_2"),
            "BISAC Category 3": DirectMappingStrategy("bisac_category_3"),
        }
        
        # Add comprehensive territorial pricing mappings
        territorial_mappings = self._create_territorial_pricing_mappings()
        additional_mappings.update(territorial_mappings)
        
        # Register all additional mappings
        for field_name, strategy in additional_mappings.items():
            self.field_registry.register_strategy(field_name, strategy)
        
        logging.info(f"Enhanced field mappings setup complete. Total mappings: {len(self.field_registry.get_registered_fields())}")

    def _setup_advanced_pricing(self):
        """Initialize advanced territorial pricing strategy."""
        try:
            from .territorial_pricing import TerritorialPricingStrategy, TerritorialPricingConfig, MarketSpecificPricingStrategy
            
            # Create pricing configuration with configurable parameters
            pricing_config = TerritorialPricingConfig(
                base_currency="USD",
                wiggle_room_percent=5.0,  # 5% wiggle room for unexpected variations
                market_access_fee_usd=0.0,  # No market access fee by default
                cache_duration_hours=24
            )
            
            # Initialize territorial pricing strategy
            territorial_strategy = TerritorialPricingStrategy(pricing_config)
            
            # Initialize market-specific pricing strategy
            self.territorial_pricing_strategy = MarketSpecificPricingStrategy(territorial_strategy)
            
            self.logging_manager.log_info("Advanced territorial pricing strategy initialized")
            
        except Exception as e:
            self.logging_manager.log_warning(f"Failed to initialize advanced pricing strategy: {e}. Using fallback pricing.")
            self.territorial_pricing_strategy = None

    def _create_territorial_pricing_mappings(self):
        """Create mapping strategies for all territorial pricing fields."""
        from .field_mapping import ComputedMappingStrategy
        
        # Define all territorial pricing fields from the LSI template
        territorial_fields = [
            # Standard international territories
            ("GC", "GC Suggested List Price (mode 2)", "GC Wholesale Discount % (Mode 2)"),
            
            # US specialized territories
            ("USBR1", "USBR1 Suggested List Price (mode 2)", "USBR1 Wholesale Discount % (Mode 2)"),
            ("USDE1", "USDE1 Suggested List Price (mode 2)", "USDE1 Wholesale Discount % (Mode 2)"),
            ("USRU1", "USRU1 Suggested List Price (mode 2)", "USRU1 Wholesale Discount % (Mode 2)"),
            ("USPL1", "USPL1 Suggested List Price (mode 2)", "USPL1 Wholesale Discount % (Mode 2)"),
            ("USKR1", "USKR1 Suggested List Price (mode 2)", "USKR1 Wholesale Discount % (Mode 2)"),
            ("USCN1", "USCN1 Suggested List Price (mode 2)", "USCN1 Wholesale Discount % (Mode 2)"),
            ("USIN1", "USIN1 Suggested List Price (mode 2)", "USIN1 Wholesale Discount % (Mode 2)"),
            ("USJP2", "USJP2 Suggested List Price(mode 2)", "USJP2 Wholesale Discount % (Mode 2)"),
            ("UAEUSD", "UAEUSD Suggested List Price (mode 2)", "UAEUSD Wholesale Discount % (Mode 2)"),
            
            # Special US territories
            ("US-Ingram-Only", "US-Ingram-Only* Suggested List Price (mode 2)", "US-Ingram-Only* Wholesale Discount % (Mode 2)"),
            ("US-Ingram-GAP", "US - Ingram - GAP * Suggested List Price (mode 2)", "US - Ingram - GAP * Wholesale Discount % (Mode 2)"),
            ("SIBI-EDUC-US", "SIBI - EDUC - US * Suggested List Price (mode 2)", "SIBI - EDUC - US * Wholesale Discount % (Mode 2)"),
        ]
        
        mappings = {}
        
        for territory_code, price_field, discount_field in territorial_fields:
            # Create computed strategies for pricing fields
            mappings[price_field] = ComputedMappingStrategy(
                lambda metadata, context, territory=territory_code: self._compute_territorial_price(metadata, territory)
            )
            mappings[discount_field] = ComputedMappingStrategy(
                lambda metadata, context, territory=territory_code: self._compute_territorial_discount(metadata, territory)
            )
        
        return mappings

    def _compute_territorial_price(self, metadata: CodexMetadata, territory: str) -> str:
        """Compute territorial pricing using advanced pricing strategies."""
        try:
            # Handle special mode 2 fields that should be blank per punch list task 11
            special_blank_territories = [
                "US-Ingram-Only", "US-Ingram-GAP", "SIBI-EDUC-US"
            ]
            
            if territory in special_blank_territories:
                return ""  # These should be blank per punch list requirements
            
            # Get base US price
            base_price = metadata.list_price_usd
            if not base_price:
                return ""
            
            # Convert to float if needed
            if isinstance(base_price, str):
                # Remove dollar sign if present
                base_price = float(base_price.replace('$', ''))
            
            # Use advanced territorial pricing if available
            if hasattr(self, 'territorial_pricing_strategy'):
                try:
                    # Get territorial configuration to determine currency
                    territorial_config = self.config.get_territorial_config(territory)
                    target_currency = territorial_config.currency if territorial_config else "USD"
                    
                    # Calculate price using advanced strategy
                    price_result = self.territorial_pricing_strategy.calculate_market_price(base_price, territory)
                    
                    if price_result["success"]:
                        return price_result["formatted_price"]
                    else:
                        self.logging_manager.log_warning(f"Advanced pricing failed for {territory}, using fallback")
                except Exception as e:
                    self.logging_manager.log_warning(f"Advanced pricing error for {territory}: {e}, using fallback")
            
            # Fallback to simple territorial configuration
            territorial_config = self.config.get_territorial_config(territory)
            if territorial_config and hasattr(territorial_config, 'pricing_multiplier'):
                adjusted_price = base_price * territorial_config.pricing_multiplier
                currency_symbol = getattr(territorial_config, 'currency', '$')
                if currency_symbol != '$':
                    # Get proper currency symbol
                    from .territorial_pricing import TerritorialPricingStrategy
                    temp_strategy = TerritorialPricingStrategy()
                    currency_symbol = temp_strategy.get_currency_symbol(currency_symbol)
                return f"{currency_symbol}{adjusted_price:.2f}"
            
            # Default: use same price as US
            return f"${base_price:.2f}"
            
        except Exception as e:
            logging.warning(f"Error computing territorial price for {territory}: {e}")
            return ""

    def _compute_territorial_discount(self, metadata: CodexMetadata, territory: str) -> str:
        """Compute territorial discount based on territory configuration."""
        try:
            # Handle special mode 2 fields that should be blank per punch list task 11
            special_blank_territories = [
                "US-Ingram-Only", "US-Ingram-GAP", "SIBI-EDUC-US"
            ]
            
            if territory in special_blank_territories:
                return ""  # These should be blank per punch list requirements
            
            # Get discount from configuration system
            imprint = metadata.imprint or "default"
            
            # Try to get territorial-specific discount
            territorial_config = self.config.get_territorial_config(territory)
            if territorial_config and hasattr(territorial_config, 'wholesale_discount_percent'):
                discount = territorial_config.wholesale_discount_percent
                if discount:
                    # Ensure it has % sign if not already present
                    if not str(discount).endswith('%'):
                        discount = f"{discount}%"
                    return discount
            
            # Fallback to default wholesale discount from config
            default_discount = self.config.get_default_value("us_wholesale_discount")  # Use us_wholesale_discount as default
            if default_discount:
                if not str(default_discount).endswith('%'):
                    default_discount = f"{default_discount}%"
                return default_discount
            
            # Final fallback
            return "40%"
            
        except Exception as e:
            logging.warning(f"Error computing territorial discount for {territory}: {e}")
            return "40%"

    def _compute_weight(self, metadata: CodexMetadata, context) -> str:
        """Compute book weight based on page count and trim size."""
        try:
            page_count = metadata.page_count or 0
            if page_count == 0:
                return ""
            
            # Basic weight calculation: approximately 0.0025 lbs per page for standard paper
            # This is a rough estimate and can be refined based on paper type and trim size
            estimated_weight = page_count * 0.0025
            return f"{estimated_weight:.2f}"
        except Exception as e:
            logging.warning(f"Error computing weight: {e}")
            return ""

    def _compute_returnability(self, metadata: CodexMetadata, context) -> str:
        """Compute returnability based on configuration."""
        try:
            # Get territory from context if available
            territory = None
            if hasattr(context, 'field_name'):
                # Try to extract territory from field name
                field_name = context.field_name
                if "Returnable" in field_name and "-" in field_name:
                    territory = field_name.split("-")[0].strip()
            
            # Default to US if territory not detected
            territory = territory or "US"
            
            # Get territorial configuration
            territorial_config = self.config.get_territorial_config(territory)
            if territorial_config and hasattr(territorial_config, 'returnability'):
                return territorial_config.returnability
            
            # Fallback to default returnability from config
            default_returnability = self.config.get_default_value("returnability")
            if default_returnability:
                return default_returnability
            
            # Final fallback based on territory
            return "Yes - Destroy" if territory == "US" else "No"
            
        except Exception as e:
            logging.warning(f"Error computing returnability for {territory if 'territory' in locals() else 'unknown'}: {e}")
            return "Yes - Destroy" if territory == "US" else "No"

    def validate_submission(self, metadata: CodexMetadata):
        """
        Validate metadata for LSI submission requirements.
        
        Args:
            metadata: CodexMetadata object to validate
            
        Returns:
            ValidationResult with validation outcomes
        """
        return self.validation_pipeline.validate(metadata)

    def generate_with_validation(self, metadata: CodexMetadata, output_path: str, **kwargs):
        """
        Generate LSI ACS CSV with validation and comprehensive reporting.
        
        Args:
            metadata: CodexMetadata object containing the book metadata
            output_path: Path where the CSV file should be saved
            **kwargs: Additional generation options
            
        Returns:
            GenerationResult with validation and generation outcomes
        """
        from .generation_result import GenerationReporter
        
        # Start comprehensive logging session
        session_id = self.logging_manager.start_generation_session(metadata, output_path)
        
        # Initialize generation reporter
        reporter = GenerationReporter()
        result = reporter.start_generation(output_path)
        
        try:
            # Store source metadata summary
            result.source_metadata_summary = {
                "title": metadata.title or "Unknown",
                "author": metadata.author or "Unknown",
                "isbn": metadata.isbn13 or "Unknown",
                "publisher": metadata.publisher or "Unknown",
                "imprint": metadata.imprint or "Unknown"
            }
            
            # Start validation timing
            self.logging_manager.start_operation_timing("validation")
            
            # Validate metadata first
            validation_result = self.validate_submission(metadata)
            
            # Log validation timing and results
            validation_time = self.logging_manager.end_operation_timing("validation")
            self.logging_manager.log_performance_metric("validation_time", validation_time)
            self.logging_manager.log_validation_summary(validation_result)
            
            # Check for blocking errors
            if validation_result.has_blocking_errors():
                error_msg = f"Validation failed with blocking errors: {validation_result.errors}"
                self.logging_manager.log_error(error_msg)
                reporter.add_error(error_msg)
                reporter.complete_generation(False, validation_result)
                self.logging_manager.complete_generation_session(False)
                return result
            
            # Log warnings if any
            if validation_result.warnings:
                warning_msg = f"Validation warnings: {validation_result.warnings}"
                self.logging_manager.log_warning(warning_msg)
                reporter.add_warning(warning_msg)
            
            # Start CSV generation timing
            self.logging_manager.start_operation_timing("csv_generation")
            
            # Generate the CSV with detailed tracking
            self._generate_with_comprehensive_logging(metadata, output_path, reporter, **kwargs)
            
            # Log CSV generation timing
            generation_time = self.logging_manager.end_operation_timing("csv_generation")
            self.logging_manager.log_performance_metric("csv_generation_time", generation_time)
            
            # Get final file size for logging
            final_file_size = os.path.getsize(output_path) if os.path.exists(output_path) else 0
            
            # Complete generation tracking
            reporter.complete_generation(True, validation_result)
            
            # Complete comprehensive logging session
            self.logging_manager.complete_generation_session(True, final_file_size)
            
            self.logging_manager.log_info(f"LSI ACS generation completed: {result.get_summary()}")
            return result
            
        except Exception as e:
            error_msg = f"Generation failed: {str(e)}"
            self.logging_manager.log_error(error_msg)
            reporter.add_error(error_msg)
            reporter.complete_generation(False, validation_result if 'validation_result' in locals() else None)
            self.logging_manager.complete_generation_session(False)
            return result

    def generate_batch_csv(self, metadata_list: List[CodexMetadata], output_path: str, **kwargs):
        """
        Generate LSI ACS CSV with multiple book rows from pipeline job.
        
        Args:
            metadata_list: List of CodexMetadata objects from pipeline
            output_path: Path where the CSV file should be saved
            **kwargs: Additional generation options
            
        Returns:
            GenerationResult with validation and generation outcomes for all books
        """
        from .generation_result import GenerationReporter
        
        # Initialize generation reporter for batch processing
        reporter = GenerationReporter()
        result = reporter.start_generation(output_path)
        
        try:
            # Read template headers once
            template_headers = self._read_template_headers()
            
            # Collect all book rows
            all_book_rows = []
            batch_validation_results = []
            
            for i, metadata in enumerate(metadata_list):
                self.logging_manager.log_info(f"Processing book {i+1}/{len(metadata_list)}: {metadata.title}")
                
                # Validate each book
                validation_result = self.validate_submission(metadata)
                batch_validation_results.append(validation_result)
                
                # Map metadata to LSI format
                lsi_data = self._map_metadata_with_comprehensive_logging(metadata, template_headers, reporter)
                all_book_rows.append(lsi_data)
            
            # Write the batch CSV with all books
            with open(output_path, 'w', encoding='utf-8-sig', newline='') as f:
                writer = csv.writer(f)
                # Write header row from template
                writer.writerow(template_headers)
                # Write all book data rows
                for book_row in all_book_rows:
                    writer.writerow(book_row)
            
            # Aggregate validation results
            total_errors = []
            total_warnings = []
            for validation_result in batch_validation_results:
                if validation_result:
                    total_errors.extend(validation_result.errors)
                    total_warnings.extend(validation_result.warnings)
            
            # Create combined validation result
            from ..verifiers.validation_framework import ValidationResult
            combined_validation = ValidationResult(
                is_valid=len(total_errors) == 0,
                field_results=[],
                errors=total_errors,
                warnings=total_warnings
            )
            
            # Complete generation tracking
            reporter.complete_generation(True, combined_validation)
            
            self.logging_manager.log_info(f"Batch LSI ACS generation completed: {len(metadata_list)} books written to {output_path}")
            return result
            
        except Exception as e:
            error_msg = f"Batch generation failed: {str(e)}"
            self.logging_manager.log_error(error_msg)
            reporter.add_error(error_msg)
            reporter.complete_generation(False, None)
            return result

    def _generate_with_comprehensive_logging(self, metadata: CodexMetadata, output_path: str, reporter, **kwargs):
        """Generate CSV with comprehensive logging and detailed field tracking."""
        # Start template reading timing
        self.logging_manager.start_operation_timing("template_reading")
        
        # Read the template to get the correct headers
        template_headers = self._read_template_headers()
        
        # Log template reading timing
        template_time = self.logging_manager.end_operation_timing("template_reading")
        self.logging_manager.log_performance_metric("template_reading_time", template_time)
        self.logging_manager.log_info(f"Template loaded with {len(template_headers)} fields")
        
        # Start field mapping timing
        self.logging_manager.start_operation_timing("field_mapping")
        
        # Map metadata to LSI format with comprehensive logging
        lsi_data = self._map_metadata_with_comprehensive_logging(metadata, template_headers, reporter)
        
        # Log field mapping timing
        mapping_time = self.logging_manager.end_operation_timing("field_mapping")
        self.logging_manager.log_performance_metric("field_mapping_time", mapping_time)
        
        # Start file writing timing
        self.logging_manager.start_operation_timing("file_writing")
        
        # Write the populated CSV
        with open(output_path, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            # Write header row from template
            writer.writerow(template_headers)
            # Write data row
            writer.writerow(lsi_data)
        
        # Log file writing timing
        writing_time = self.logging_manager.end_operation_timing("file_writing")
        self.logging_manager.log_performance_metric("file_writing_time", writing_time)
        
        self.logging_manager.log_info(f"LSI ACS CSV generated successfully: {output_path}")

    def _map_metadata_with_comprehensive_logging(self, metadata: CodexMetadata, headers: list, reporter) -> list:
        """Map metadata to LSI format with comprehensive logging and detailed tracking."""
        from .field_mapping import MappingContext
        import time
        
        results = []
        
        for header in headers:
            # Start timing for individual field mapping
            field_start_time = time.time()
            
            strategy = self.field_registry.get_strategy(header)
            if strategy:
                try:
                    context = MappingContext(
                        field_name=header,
                        lsi_headers=headers,
                        current_row_data={},
                        metadata=metadata
                    )
                    
                    # Get source value for logging
                    source_value = None
                    if hasattr(strategy, 'metadata_field'):
                        source_value = getattr(metadata, strategy.metadata_field, None)
                    
                    if strategy.validate_input(metadata, context):
                        value = strategy.map_field(metadata, context)
                        
                        # Calculate processing time
                        processing_time_ms = (time.time() - field_start_time) * 1000
                        
                        # Determine mapping type for tracking
                        mapping_type = "direct"
                        strategy_name = type(strategy).__name__
                        if "Computed" in strategy_name:
                            mapping_type = "computed"
                        elif "Default" in strategy_name:
                            mapping_type = "default"
                        elif "Conditional" in strategy_name:
                            mapping_type = "conditional"
                        elif "LLM" in strategy_name:
                            mapping_type = "llm_completion"
                        
                        # Log field mapping with comprehensive details
                        self.logging_manager.log_field_mapping(
                            field_name=header,
                            source_value=source_value,
                            mapped_value=value,
                            mapping_strategy=mapping_type,
                            processing_time_ms=processing_time_ms
                        )
                        
                        # Track the field mapping for reporter
                        reporter.track_field_mapping(header, value, mapping_type)
                        results.append(str(value) if value is not None else '')
                        
                    else:
                        processing_time_ms = (time.time() - field_start_time) * 1000
                        warning_msg = f"Validation failed for field '{header}', using empty value"
                        
                        # Log field mapping with validation failure
                        self.logging_manager.log_field_mapping(
                            field_name=header,
                            source_value=source_value,
                            mapped_value="",
                            mapping_strategy="validation_failed",
                            processing_time_ms=processing_time_ms,
                            warnings=[warning_msg]
                        )
                        
                        self.logging_manager.log_warning(warning_msg)
                        reporter.add_warning(warning_msg)
                        reporter.track_field_mapping(header, "", "validation_failed")
                        results.append('')
                        
                except Exception as e:
                    processing_time_ms = (time.time() - field_start_time) * 1000
                    error_msg = f"Error mapping field '{header}': {e}"
                    
                    # Log field mapping with error
                    self.logging_manager.log_field_mapping(
                        field_name=header,
                        source_value=source_value,
                        mapped_value="",
                        mapping_strategy="error",
                        processing_time_ms=processing_time_ms,
                        errors=[error_msg]
                    )
                    
                    self.logging_manager.log_error(error_msg)
                    reporter.add_error(error_msg)
                    reporter.track_field_mapping(header, "", "error")
                    results.append('')
            else:
                processing_time_ms = (time.time() - field_start_time) * 1000
                
                # Log field mapping with no strategy
                self.logging_manager.log_field_mapping(
                    field_name=header,
                    source_value=None,
                    mapped_value="",
                    mapping_strategy="no_strategy",
                    processing_time_ms=processing_time_ms,
                    warnings=[f"No mapping strategy registered for field '{header}'"]
                )
                
                # No strategy registered, use empty value
                reporter.track_field_mapping(header, "", "no_strategy")
                results.append('')
        
        return results

    def _generate_with_tracking(self, metadata: CodexMetadata, output_path: str, reporter, **kwargs):
        """Generate CSV with detailed field tracking for reporting."""
        # Read the template to get the correct headers
        template_headers = self._read_template_headers()
        
        # Map metadata to LSI format with tracking
        lsi_data = self._map_metadata_with_tracking(metadata, template_headers, reporter)

        # Write the populated CSV
        with open(output_path, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            # Write header row from template
            writer.writerow(template_headers)
            # Write data row
            writer.writerow(lsi_data)
        
        logging.info(f"LSI ACS CSV generated successfully: {output_path}")

    def _map_metadata_with_tracking(self, metadata: CodexMetadata, headers: list, reporter) -> list:
        """Map metadata to LSI format with detailed tracking for reporting."""
        from .field_mapping import MappingContext
        
        results = []
        
        for header in headers:
            strategy = self.field_registry.get_strategy(header)
            if strategy:
                try:
                    context = MappingContext(
                        field_name=header,
                        lsi_headers=headers,
                        current_row_data={},
                        metadata=metadata
                    )
                    
                    if strategy.validate_input(metadata, context):
                        value = strategy.map_field(metadata, context)
                        
                        # Determine mapping type for tracking
                        mapping_type = "direct"
                        strategy_name = type(strategy).__name__
                        if "Computed" in strategy_name:
                            mapping_type = "computed"
                        elif "Default" in strategy_name:
                            mapping_type = "default"
                        
                        # Track the field mapping
                        reporter.track_field_mapping(header, value, mapping_type)
                        results.append(str(value) if value is not None else '')
                        
                    else:
                        warning_msg = f"Validation failed for field '{header}', using empty value"
                        logging.warning(warning_msg)
                        reporter.add_warning(warning_msg)
                        reporter.track_field_mapping(header, "", "validation_failed")
                        results.append('')
                        
                except Exception as e:
                    error_msg = f"Error mapping field '{header}': {e}"
                    logging.error(error_msg)
                    reporter.add_error(error_msg)
                    reporter.track_field_mapping(header, "", "error")
                    results.append('')
            else:
                # No strategy registered, use empty value
                reporter.track_field_mapping(header, "", "no_strategy")
                results.append('')
        
        return results

    def generate(self, metadata: CodexMetadata, output_path: str, **kwargs):
        """
        Generates an LSI ACS CSV file from metadata.

        Args:
            metadata: CodexMetadata object containing the book metadata
            output_path: Path where the CSV file should be saved
        """
        try:
            # Load template and populate with metadata
            self._create_lsi_csv(metadata, output_path)
            logging.info(f"LSI ACS CSV generated successfully: {output_path}")
        except Exception as e:
            logging.error(f"Failed to generate LSI ACS CSV: {e}", exc_info=True)
            raise

    def generate_batch(self, metadata_list: list, output_path: str, **kwargs):
        """
        Generates an LSI ACS CSV file from multiple metadata objects.
        All books will be included as rows in a single CSV file.

        Args:
            metadata_list: List of CodexMetadata objects containing book metadata
            output_path: Path where the CSV file should be saved
        """
        try:
            self._create_batch_lsi_csv(metadata_list, output_path)
            logging.info(f"Batch LSI ACS CSV generated successfully with {len(metadata_list)} books: {output_path}")
        except Exception as e:
            logging.error(f"Failed to generate batch LSI ACS CSV: {e}", exc_info=True)
            raise

    def _create_batch_lsi_csv(self, metadata_list: list, output_path: str):
        """Creates the LSI ACS CSV file from multiple metadata objects using the proper template."""
        # Read the template to get the correct headers
        template_headers = self._read_template_headers()
        
        # Write the populated CSV with all books
        with open(output_path, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            # Write header row from template
            writer.writerow(template_headers)
            
            # Write data row for each book
            for metadata in metadata_list:
                lsi_data = self._map_metadata_to_lsi_template(metadata, template_headers)
                writer.writerow(lsi_data)ved
        """
        try:
            self._create_batch_lsi_csv(metadata_list, output_path)
            logging.info(f"Batch LSI ACS CSV generated successfully with {len(metadata_list)} books: {output_path}")
        except Exception as e:
            logging.error(f"Failed to generate batch LSI ACS CSV: {e}", exc_info=True)
            raise

    def _create_batch_lsi_csv(self, metadata_list: list, output_path: str):
        """Creates the LSI ACS CSV file from multiple metadata objects using the proper template."""
        # Read the template to get the correct headers
        template_headers = self._read_template_headers()
        
        # Write the populated CSV with all books
        with open(output_path, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            # Write header row from template
            writer.writerow(template_headers)
            
            # Write data row for each book
            for metadata in metadata_list:
                lsi_data = self._map_metadata_to_lsi_template(metadata, template_headers)
                writer.writerow(lsi_data)ved
        """
        try:
            self._create_batch_lsi_csv(metadata_list, output_path)
            logging.info(f"Batch LSI ACS CSV generated successfully with {len(metadata_list)} books: {output_path}")
        except Exception as e:
            logging.error(f"Failed to generate batch LSI ACS CSV: {e}", exc_info=True)
            raise

    def _create_lsi_csv(self, metadata: CodexMetadata, output_path: str):
        """Creates the LSI ACS CSV file from metadata using the proper template."""
        # Read the template to get the correct headers
        template_headers = self._read_template_headers()
        
        # Map metadata to LSI format using template headers
        lsi_data = self._map_metadata_to_lsi_template(metadata, template_headers)

        # Write the populated CSV
        with open(output_path, 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.writer(f)
            # Write header row from template
            writer.writerow(template_headers)
            # Write data row
            writer.writerow(lsi_data)

    def _read_template_headers(self) -> list:
        """Reads the header row from the LSI template CSV file."""
        try:
            with open(self.template_path, 'r', encoding='utf-8-sig', newline='') as f:
                reader = csv.reader(f)
                headers = next(reader)
                return headers
        except Exception as e:
            logging.error(f"Failed to read template headers from {self.template_path}: {e}")
            raise

    def _map_metadata_to_lsi_template(self, metadata: CodexMetadata, headers: list) -> list:
        """Maps CodexMetadata to LSI template format using field mapping registry."""
        # Use the field mapping registry to generate values in header order
        return self.field_registry.apply_mappings_ordered(metadata, headers)

    def _format_keywords(self, keywords: str) -> str:
        """Formats keywords by removing unwanted text and fixing spacing."""
        if not keywords:
            return ''
        
        # Remove "#Bibliographic Key Phrases" if present
        formatted = keywords.replace('#Bibliographic Key Phrases', '').strip()
        
        # Add space after semicolons if missing
        formatted = formatted.replace(';', '; ').replace(';  ', '; ')
        
        return formatted

    def _format_price(self, price) -> str:
        """Formats price as currency string."""
        if not price:
            return '$19.99'  # Default price
        
        if isinstance(price, (int, float)):
            return f'${price:.2f}'
        
        # If already a string, ensure it starts with $
        price_str = str(price)
        if not price_str.startswith('$'):
            try:
                price_float = float(price_str)
                return f'${price_float:.2f}'
            except ValueError:
                return price_str
        
        return price_str